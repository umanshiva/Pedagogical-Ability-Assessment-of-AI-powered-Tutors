{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11547141,"sourceType":"datasetVersion","datasetId":7241370}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"6cdca233-39e6-4e0d-9026-031aa5d05ae4","cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:41:59.497904Z","iopub.execute_input":"2025-04-24T15:41:59.498451Z","iopub.status.idle":"2025-04-24T15:41:59.510321Z","shell.execute_reply.started":"2025-04-24T15:41:59.498430Z","shell.execute_reply":"2025-04-24T15:41:59.509579Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/json-data/assignment_3_ai_tutors_dataset.json\n","output_type":"stream"}],"execution_count":24},{"id":"e1185388","cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import BertForSequenceClassification, BertTokenizer\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport pandas as pd\nimport json\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:42:03.487666Z","iopub.execute_input":"2025-04-24T15:42:03.488043Z","iopub.status.idle":"2025-04-24T15:42:03.492335Z","shell.execute_reply.started":"2025-04-24T15:42:03.488023Z","shell.execute_reply":"2025-04-24T15:42:03.491577Z"}},"outputs":[],"execution_count":25},{"id":"e48287d9","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:42:07.411428Z","iopub.execute_input":"2025-04-24T15:42:07.411704Z","iopub.status.idle":"2025-04-24T15:42:07.415476Z","shell.execute_reply.started":"2025-04-24T15:42:07.411682Z","shell.execute_reply":"2025-04-24T15:42:07.414732Z"}},"outputs":[],"execution_count":26},{"id":"1a1a4161","cell_type":"code","source":"class FocalLossWithWeights(nn.Module):\n    def __init__(self, weight=None, gamma=2.0):\n        super(FocalLossWithWeights, self).__init__()\n        self.weight = weight\n        self.gamma = gamma\n        self.ce = nn.CrossEntropyLoss(reduction='none', weight=weight)\n\n    def forward(self, inputs, targets):\n        logp = self.ce(inputs, targets)\n        p = torch.exp(-logp)\n        loss = (1 - p) ** self.gamma * logp\n        return loss.mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:42:11.049072Z","iopub.execute_input":"2025-04-24T15:42:11.049341Z","iopub.status.idle":"2025-04-24T15:42:11.054570Z","shell.execute_reply.started":"2025-04-24T15:42:11.049325Z","shell.execute_reply":"2025-04-24T15:42:11.053784Z"}},"outputs":[],"execution_count":27},{"id":"e1113798","cell_type":"code","source":"# ---------- Dataset Definition ----------\nclass TutorEvalSingleTaskDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        return {\n            'input_ids': self.encodings['input_ids'][idx],\n            'attention_mask': self.encodings['attention_mask'][idx],\n            'labels': self.labels[idx]\n        }\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:42:14.984347Z","iopub.execute_input":"2025-04-24T15:42:14.985227Z","iopub.status.idle":"2025-04-24T15:42:14.989888Z","shell.execute_reply.started":"2025-04-24T15:42:14.985198Z","shell.execute_reply":"2025-04-24T15:42:14.989120Z"}},"outputs":[],"execution_count":28},{"id":"0c434c87","cell_type":"code","source":"# ---------- Preprocessing ----------\ndef load_and_flatten(json_path):\n    with open(json_path) as f:\n        data = json.load(f)\n\n    rows = []\n    for instance in data:\n        convo_id = instance[\"conversation_id\"]\n        history = instance[\"conversation_history\"]\n        for tutor_id, tutor_data in instance[\"tutor_responses\"].items():\n            row = {\n                \"conversation_id\": convo_id,\n                \"tutor_id\": tutor_id,\n                \"conversation_history\": history,\n                \"tutor_response\": tutor_data[\"response\"],\n                \"Mistake_Identification\": tutor_data[\"annotation\"][\"Mistake_Identification\"],\n                \"Mistake_Location\": tutor_data[\"annotation\"][\"Mistake_Location\"],\n                \"Pedagogical_Guidance\": tutor_data[\"annotation\"][\"Providing_Guidance\"],\n                \"Actionability\": tutor_data[\"annotation\"][\"Actionability\"]\n            }\n            rows.append(row)\n    return pd.DataFrame(rows)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:42:18.686049Z","iopub.execute_input":"2025-04-24T15:42:18.686282Z","iopub.status.idle":"2025-04-24T15:42:18.691757Z","shell.execute_reply.started":"2025-04-24T15:42:18.686267Z","shell.execute_reply":"2025-04-24T15:42:18.691052Z"}},"outputs":[],"execution_count":29},{"id":"5c2930e4","cell_type":"code","source":"def build_input_text(row):\n    return f\"Context:\\n{row['conversation_history']}\\n\\nTutor Response:\\n{row['tutor_response']}\"\n\nLABEL_MAP = {\"Yes\": 0, \"To some extent\": 1, \"No\": 2}\nMERGED_LABEL_MAP = {\"Yes\": 1, \"To some extent\": 1, \"No\": 0}\n\ndef encode_labels(df):\n    for task in [\"Mistake_Identification\", \"Mistake_Location\", \"Pedagogical_Guidance\", \"Actionability\"]:\n        df[f\"{task}_label\"] = df[task].map(LABEL_MAP)\n        df[f\"{task}_binary\"] = df[task].map(MERGED_LABEL_MAP)\n    return df\n\ndef tokenize_inputs(tokenizer, texts, max_length=256):\n    return tokenizer(\n        texts,\n        add_special_tokens=True,\n        truncation=True,\n        padding=True,\n        max_length=max_length,\n        return_tensors=\"pt\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:42:22.492947Z","iopub.execute_input":"2025-04-24T15:42:22.493493Z","iopub.status.idle":"2025-04-24T15:42:22.498496Z","shell.execute_reply.started":"2025-04-24T15:42:22.493471Z","shell.execute_reply":"2025-04-24T15:42:22.497664Z"}},"outputs":[],"execution_count":30},{"id":"5a05da72","cell_type":"code","source":"def preprocess_dataset(json_path, task_label):\n    df = load_and_flatten(json_path)\n    df[\"input_text\"] = df.apply(build_input_text, axis=1)\n    df = encode_labels(df)\n\n    train_df, val_df = train_test_split(df, test_size=0.1, stratify=df[task_label], random_state=42)\n\n    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n    train_enc = tokenize_inputs(tokenizer, train_df[\"input_text\"].tolist())\n    val_enc = tokenize_inputs(tokenizer, val_df[\"input_text\"].tolist())\n\n    train_labels = torch.tensor(train_df[task_label].tolist())\n    val_labels = torch.tensor(val_df[task_label].tolist())\n\n    train_dataset = TutorEvalSingleTaskDataset(train_enc, train_labels)\n    val_dataset = TutorEvalSingleTaskDataset(val_enc, val_labels)\n\n    return train_dataset, val_dataset, tokenizer, df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:42:25.999273Z","iopub.execute_input":"2025-04-24T15:42:25.999515Z","iopub.status.idle":"2025-04-24T15:42:26.005089Z","shell.execute_reply.started":"2025-04-24T15:42:25.999498Z","shell.execute_reply":"2025-04-24T15:42:26.004276Z"}},"outputs":[],"execution_count":31},{"id":"35160396-a63a-4059-95d3-0161f542b714","cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\ndef get_class_weights(labels, num_classes):\n    class_weights = compute_class_weight(class_weight='balanced', classes=np.arange(num_classes), y=labels)\n    return torch.tensor(class_weights, dtype=torch.float).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:42:31.294424Z","iopub.execute_input":"2025-04-24T15:42:31.295214Z","iopub.status.idle":"2025-04-24T15:42:31.300324Z","shell.execute_reply.started":"2025-04-24T15:42:31.295183Z","shell.execute_reply":"2025-04-24T15:42:31.299419Z"}},"outputs":[],"execution_count":32},{"id":"8aee3adf","cell_type":"code","source":"# ---------- Model ----------\nclass SingleTaskBertClassifier(nn.Module):\n    def __init__(self, num_labels):\n        super().__init__()\n        self.bert = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n\n    def forward(self, input_ids, attention_mask):\n        return self.bert(input_ids=input_ids, attention_mask=attention_mask).logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:42:34.958299Z","iopub.execute_input":"2025-04-24T15:42:34.958569Z","iopub.status.idle":"2025-04-24T15:42:34.963255Z","shell.execute_reply.started":"2025-04-24T15:42:34.958548Z","shell.execute_reply":"2025-04-24T15:42:34.962360Z"}},"outputs":[],"execution_count":33},{"id":"237b5857","cell_type":"code","source":"# ---------- Training ----------\ndef evaluate_model(model, val_loader):\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].cpu().numpy()\n\n            outputs = model(input_ids, attention_mask)\n            preds = torch.argmax(outputs, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels)\n\n    acc = accuracy_score(all_labels, all_preds)\n    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n    print(f\"Validation Accuracy: {acc:.4f}  Validation Macro F1: {macro_f1:.4f}\")\n    print(classification_report(all_labels, all_preds, target_names=[\"Yes\", \"To some extent\", \"No\"], zero_division=0))\n\ndef train_model(loss_type, train_loader, val_loader, num_labels, epochs=15):\n    print(f\"\\n🔁 Training with: {loss_type.upper()} Loss\\n\")\n\n    model = SingleTaskBertClassifier(num_labels).to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n\n    train_labels_list = [label.item() for batch in train_loader for label in batch['labels']]\n    class_weights = get_class_weights(train_labels_list, num_labels)\n\n    if loss_type == \"focal\":\n        criterion = FocalLossWithWeights(class_weights)\n    elif loss_type == \"smoothing\":\n        criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n    else:\n        criterion = nn.CrossEntropyLoss(weight=class_weights)\n\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n            optimizer.zero_grad()\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(input_ids, attention_mask)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n\n        avg_loss = total_loss / len(train_loader)\n        print(f\"Epoch {epoch+1} Loss: {avg_loss:.4f}\")\n        evaluate_model(model, val_loader)\n\n        '''if(epoch==epochs):\n            save_path = f\"/kaggle/working/best_model_{loss_type}.pth\"\n            torch.save(model.state_dict(), save_path)\n            print(f\"✅ Model weights saved to {save_path}\")'''\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:42:38.819672Z","iopub.execute_input":"2025-04-24T15:42:38.820027Z","iopub.status.idle":"2025-04-24T15:42:38.829375Z","shell.execute_reply.started":"2025-04-24T15:42:38.820000Z","shell.execute_reply":"2025-04-24T15:42:38.828644Z"}},"outputs":[],"execution_count":34},{"id":"dd999b1b","cell_type":"code","source":"# ---------- Run ----------\njson_path = \"/kaggle/input/json-data/assignment_3_ai_tutors_dataset.json\"\ntrain_dataset, val_dataset, tokenizer, df = preprocess_dataset(json_path, \"Mistake_Identification_label\")\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=4)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:42:44.715077Z","iopub.execute_input":"2025-04-24T15:42:44.715345Z","iopub.status.idle":"2025-04-24T15:42:53.299771Z","shell.execute_reply.started":"2025-04-24T15:42:44.715324Z","shell.execute_reply":"2025-04-24T15:42:53.299052Z"}},"outputs":[],"execution_count":35},{"id":"4db195cc-feba-4d7d-8252-8b67720dbb9a","cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:43:04.817589Z","iopub.execute_input":"2025-04-24T15:43:04.817881Z","iopub.status.idle":"2025-04-24T15:43:04.835399Z","shell.execute_reply.started":"2025-04-24T15:43:04.817835Z","shell.execute_reply":"2025-04-24T15:43:04.834437Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"                                conversation_id     tutor_id  \\\n0      221-362eb11a-f190-42a6-b2a4-985fafdcfa9e       Sonnet   \n1      221-362eb11a-f190-42a6-b2a4-985fafdcfa9e    Llama318B   \n2      221-362eb11a-f190-42a6-b2a4-985fafdcfa9e  Llama31405B   \n3      221-362eb11a-f190-42a6-b2a4-985fafdcfa9e         GPT4   \n4      221-362eb11a-f190-42a6-b2a4-985fafdcfa9e      Mistral   \n...                                         ...          ...   \n2471  5910-25617a89-a4ae-47bb-8812-d6b39fa4e691      Mistral   \n2472  5910-25617a89-a4ae-47bb-8812-d6b39fa4e691         Phi3   \n2473  5910-25617a89-a4ae-47bb-8812-d6b39fa4e691       Sonnet   \n2474  5910-25617a89-a4ae-47bb-8812-d6b39fa4e691       Expert   \n2475  5910-25617a89-a4ae-47bb-8812-d6b39fa4e691    Llama318B   \n\n                                   conversation_history  \\\n0     Tutor: Hi, could you please provide a step-by-...   \n1     Tutor: Hi, could you please provide a step-by-...   \n2     Tutor: Hi, could you please provide a step-by-...   \n3     Tutor: Hi, could you please provide a step-by-...   \n4     Tutor: Hi, could you please provide a step-by-...   \n...                                                 ...   \n2471  Tutor: Hi, could you please provide a step-by-...   \n2472  Tutor: Hi, could you please provide a step-by-...   \n2473  Tutor: Hi, could you please provide a step-by-...   \n2474  Tutor: Hi, could you please provide a step-by-...   \n2475  Tutor: Hi, could you please provide a step-by-...   \n\n                                         tutor_response  \\\n0     Great, you've correctly identified the cost of...   \n1     Now that we know the cost of 1 pound of meat i...   \n2     You're close, but I notice that you calculated...   \n3     That's correct. So, if 1 pound of meat costs $...   \n4     It seems like you've calculated the cost as if...   \n...                                                 ...   \n2471  It seems there might be a misunderstanding in ...   \n2472  To solve this problem, we need to add the numb...   \n2473  That's a great start and I like how you worked...   \n2474  Okay. So Hector gave 5 less than four times as...   \n2475  That's a good attempt, but let's examine the s...   \n\n     Mistake_Identification Mistake_Location Pedagogical_Guidance  \\\n0                       Yes              Yes                  Yes   \n1                       Yes   To some extent       To some extent   \n2                       Yes              Yes                  Yes   \n3                       Yes              Yes                  Yes   \n4                       Yes              Yes                  Yes   \n...                     ...              ...                  ...   \n2471                    Yes              Yes       To some extent   \n2472                     No               No                   No   \n2473                    Yes              Yes                  Yes   \n2474                    Yes              Yes                  Yes   \n2475         To some extent   To some extent                  Yes   \n\n       Actionability                                         input_text  \\\n0                Yes  Context:\\nTutor: Hi, could you please provide ...   \n1     To some extent  Context:\\nTutor: Hi, could you please provide ...   \n2                Yes  Context:\\nTutor: Hi, could you please provide ...   \n3                Yes  Context:\\nTutor: Hi, could you please provide ...   \n4                Yes  Context:\\nTutor: Hi, could you please provide ...   \n...              ...                                                ...   \n2471             Yes  Context:\\nTutor: Hi, could you please provide ...   \n2472              No  Context:\\nTutor: Hi, could you please provide ...   \n2473             Yes  Context:\\nTutor: Hi, could you please provide ...   \n2474             Yes  Context:\\nTutor: Hi, could you please provide ...   \n2475             Yes  Context:\\nTutor: Hi, could you please provide ...   \n\n      Mistake_Identification_label  Mistake_Identification_binary  \\\n0                                0                              1   \n1                                0                              1   \n2                                0                              1   \n3                                0                              1   \n4                                0                              1   \n...                            ...                            ...   \n2471                             0                              1   \n2472                             2                              0   \n2473                             0                              1   \n2474                             0                              1   \n2475                             1                              1   \n\n      Mistake_Location_label  Mistake_Location_binary  \\\n0                          0                        1   \n1                          1                        1   \n2                          0                        1   \n3                          0                        1   \n4                          0                        1   \n...                      ...                      ...   \n2471                       0                        1   \n2472                       2                        0   \n2473                       0                        1   \n2474                       0                        1   \n2475                       1                        1   \n\n      Pedagogical_Guidance_label  Pedagogical_Guidance_binary  \\\n0                              0                            1   \n1                              1                            1   \n2                              0                            1   \n3                              0                            1   \n4                              0                            1   \n...                          ...                          ...   \n2471                           1                            1   \n2472                           2                            0   \n2473                           0                            1   \n2474                           0                            1   \n2475                           0                            1   \n\n      Actionability_label  Actionability_binary  \n0                       0                     1  \n1                       1                     1  \n2                       0                     1  \n3                       0                     1  \n4                       0                     1  \n...                   ...                   ...  \n2471                    0                     1  \n2472                    2                     0  \n2473                    0                     1  \n2474                    0                     1  \n2475                    0                     1  \n\n[2476 rows x 17 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>conversation_id</th>\n      <th>tutor_id</th>\n      <th>conversation_history</th>\n      <th>tutor_response</th>\n      <th>Mistake_Identification</th>\n      <th>Mistake_Location</th>\n      <th>Pedagogical_Guidance</th>\n      <th>Actionability</th>\n      <th>input_text</th>\n      <th>Mistake_Identification_label</th>\n      <th>Mistake_Identification_binary</th>\n      <th>Mistake_Location_label</th>\n      <th>Mistake_Location_binary</th>\n      <th>Pedagogical_Guidance_label</th>\n      <th>Pedagogical_Guidance_binary</th>\n      <th>Actionability_label</th>\n      <th>Actionability_binary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n      <td>Sonnet</td>\n      <td>Tutor: Hi, could you please provide a step-by-...</td>\n      <td>Great, you've correctly identified the cost of...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Context:\\nTutor: Hi, could you please provide ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n      <td>Llama318B</td>\n      <td>Tutor: Hi, could you please provide a step-by-...</td>\n      <td>Now that we know the cost of 1 pound of meat i...</td>\n      <td>Yes</td>\n      <td>To some extent</td>\n      <td>To some extent</td>\n      <td>To some extent</td>\n      <td>Context:\\nTutor: Hi, could you please provide ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n      <td>Llama31405B</td>\n      <td>Tutor: Hi, could you please provide a step-by-...</td>\n      <td>You're close, but I notice that you calculated...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Context:\\nTutor: Hi, could you please provide ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n      <td>GPT4</td>\n      <td>Tutor: Hi, could you please provide a step-by-...</td>\n      <td>That's correct. So, if 1 pound of meat costs $...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Context:\\nTutor: Hi, could you please provide ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n      <td>Mistral</td>\n      <td>Tutor: Hi, could you please provide a step-by-...</td>\n      <td>It seems like you've calculated the cost as if...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Context:\\nTutor: Hi, could you please provide ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2471</th>\n      <td>5910-25617a89-a4ae-47bb-8812-d6b39fa4e691</td>\n      <td>Mistral</td>\n      <td>Tutor: Hi, could you please provide a step-by-...</td>\n      <td>It seems there might be a misunderstanding in ...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>To some extent</td>\n      <td>Yes</td>\n      <td>Context:\\nTutor: Hi, could you please provide ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2472</th>\n      <td>5910-25617a89-a4ae-47bb-8812-d6b39fa4e691</td>\n      <td>Phi3</td>\n      <td>Tutor: Hi, could you please provide a step-by-...</td>\n      <td>To solve this problem, we need to add the numb...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Context:\\nTutor: Hi, could you please provide ...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2473</th>\n      <td>5910-25617a89-a4ae-47bb-8812-d6b39fa4e691</td>\n      <td>Sonnet</td>\n      <td>Tutor: Hi, could you please provide a step-by-...</td>\n      <td>That's a great start and I like how you worked...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Context:\\nTutor: Hi, could you please provide ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2474</th>\n      <td>5910-25617a89-a4ae-47bb-8812-d6b39fa4e691</td>\n      <td>Expert</td>\n      <td>Tutor: Hi, could you please provide a step-by-...</td>\n      <td>Okay. So Hector gave 5 less than four times as...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Context:\\nTutor: Hi, could you please provide ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2475</th>\n      <td>5910-25617a89-a4ae-47bb-8812-d6b39fa4e691</td>\n      <td>Llama318B</td>\n      <td>Tutor: Hi, could you please provide a step-by-...</td>\n      <td>That's a good attempt, but let's examine the s...</td>\n      <td>To some extent</td>\n      <td>To some extent</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Context:\\nTutor: Hi, could you please provide ...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2476 rows × 17 columns</p>\n</div>"},"metadata":{}}],"execution_count":36},{"id":"0b018552-b3cf-4415-b545-ce26a37a308f","cell_type":"code","source":"for loss_name in [\"ce\", \"smoothing\", \"focal\"]:\n    train_model(loss_name, train_loader, val_loader, num_labels=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:43:23.922124Z","iopub.execute_input":"2025-04-24T15:43:23.922612Z","iopub.status.idle":"2025-04-24T17:14:26.236034Z","shell.execute_reply.started":"2025-04-24T15:43:23.922592Z","shell.execute_reply":"2025-04-24T17:14:26.235258Z"}},"outputs":[{"name":"stdout","text":"\n🔁 Training with: CE Loss\n\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEpoch 1/15: 100%|██████████| 557/557 [01:58<00:00,  4.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Loss: 1.0134\nValidation Accuracy: 0.7823  Validation Macro F1: 0.2926\n                precision    recall  f1-score   support\n\n           Yes       0.78      1.00      0.88       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.00      0.00      0.00        37\n\n      accuracy                           0.78       248\n     macro avg       0.26      0.33      0.29       248\n  weighted avg       0.61      0.78      0.69       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Loss: 0.9611\nValidation Accuracy: 0.7702  Validation Macro F1: 0.3642\n                precision    recall  f1-score   support\n\n           Yes       0.79      0.97      0.87       194\nTo some extent       0.30      0.18      0.22        17\n            No       0.00      0.00      0.00        37\n\n      accuracy                           0.77       248\n     macro avg       0.36      0.38      0.36       248\n  weighted avg       0.64      0.77      0.70       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Loss: 0.9191\nValidation Accuracy: 0.6855  Validation Macro F1: 0.4332\n                precision    recall  f1-score   support\n\n           Yes       0.83      0.80      0.81       194\nTo some extent       0.25      0.18      0.21        17\n            No       0.24      0.32      0.28        37\n\n      accuracy                           0.69       248\n     macro avg       0.44      0.43      0.43       248\n  weighted avg       0.70      0.69      0.69       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/15: 100%|██████████| 557/557 [01:57<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Loss: 0.8594\nValidation Accuracy: 0.7097  Validation Macro F1: 0.4975\n                precision    recall  f1-score   support\n\n           Yes       0.85      0.80      0.83       194\nTo some extent       0.26      0.41      0.32        17\n            No       0.34      0.35      0.35        37\n\n      accuracy                           0.71       248\n     macro avg       0.48      0.52      0.50       248\n  weighted avg       0.74      0.71      0.72       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Loss: 0.8091\nValidation Accuracy: 0.7298  Validation Macro F1: 0.4910\n                precision    recall  f1-score   support\n\n           Yes       0.85      0.85      0.85       194\nTo some extent       0.21      0.47      0.29        17\n            No       0.56      0.24      0.34        37\n\n      accuracy                           0.73       248\n     macro avg       0.54      0.52      0.49       248\n  weighted avg       0.76      0.73      0.73       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 Loss: 0.7531\nValidation Accuracy: 0.7984  Validation Macro F1: 0.5135\n                precision    recall  f1-score   support\n\n           Yes       0.83      0.95      0.89       194\nTo some extent       0.50      0.24      0.32        17\n            No       0.53      0.24      0.33        37\n\n      accuracy                           0.80       248\n     macro avg       0.62      0.48      0.51       248\n  weighted avg       0.76      0.80      0.77       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 Loss: 0.7208\nValidation Accuracy: 0.7056  Validation Macro F1: 0.4745\n                precision    recall  f1-score   support\n\n           Yes       0.85      0.81      0.83       194\nTo some extent       0.18      0.35      0.24        17\n            No       0.39      0.32      0.35        37\n\n      accuracy                           0.71       248\n     macro avg       0.47      0.50      0.47       248\n  weighted avg       0.74      0.71      0.72       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 Loss: 0.7016\nValidation Accuracy: 0.7621  Validation Macro F1: 0.5018\n                precision    recall  f1-score   support\n\n           Yes       0.84      0.89      0.87       194\nTo some extent       0.20      0.29      0.24        17\n            No       0.61      0.30      0.40        37\n\n      accuracy                           0.76       248\n     macro avg       0.55      0.49      0.50       248\n  weighted avg       0.77      0.76      0.75       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 Loss: 0.6931\nValidation Accuracy: 0.6089  Validation Macro F1: 0.4357\n                precision    recall  f1-score   support\n\n           Yes       0.83      0.66      0.74       194\nTo some extent       0.22      0.29      0.25        17\n            No       0.24      0.46      0.32        37\n\n      accuracy                           0.61       248\n     macro avg       0.43      0.47      0.44       248\n  weighted avg       0.70      0.61      0.64       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 Loss: 0.7067\nValidation Accuracy: 0.7379  Validation Macro F1: 0.4628\n                precision    recall  f1-score   support\n\n           Yes       0.84      0.87      0.85       194\nTo some extent       0.25      0.18      0.21        17\n            No       0.33      0.32      0.33        37\n\n      accuracy                           0.74       248\n     macro avg       0.47      0.46      0.46       248\n  weighted avg       0.72      0.74      0.73       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/15: 100%|██████████| 557/557 [01:57<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 Loss: 0.6397\nValidation Accuracy: 0.7863  Validation Macro F1: 0.4768\n                precision    recall  f1-score   support\n\n           Yes       0.83      0.94      0.88       194\nTo some extent       0.21      0.18      0.19        17\n            No       0.64      0.24      0.35        37\n\n      accuracy                           0.79       248\n     macro avg       0.56      0.45      0.48       248\n  weighted avg       0.76      0.79      0.76       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 Loss: 0.6249\nValidation Accuracy: 0.6976  Validation Macro F1: 0.4543\n                precision    recall  f1-score   support\n\n           Yes       0.84      0.80      0.82       194\nTo some extent       0.16      0.24      0.19        17\n            No       0.35      0.35      0.35        37\n\n      accuracy                           0.70       248\n     macro avg       0.45      0.46      0.45       248\n  weighted avg       0.72      0.70      0.71       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 Loss: 0.6325\nValidation Accuracy: 0.6331  Validation Macro F1: 0.4550\n                precision    recall  f1-score   support\n\n           Yes       0.87      0.70      0.77       194\nTo some extent       0.12      0.41      0.18        17\n            No       0.44      0.38      0.41        37\n\n      accuracy                           0.63       248\n     macro avg       0.47      0.50      0.45       248\n  weighted avg       0.75      0.63      0.68       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/15: 100%|██████████| 557/557 [01:57<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 Loss: 0.6273\nValidation Accuracy: 0.7419  Validation Macro F1: 0.4865\n                precision    recall  f1-score   support\n\n           Yes       0.84      0.87      0.85       194\nTo some extent       0.13      0.24      0.17        17\n            No       0.67      0.32      0.44        37\n\n      accuracy                           0.74       248\n     macro avg       0.55      0.48      0.49       248\n  weighted avg       0.77      0.74      0.74       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/15: 100%|██████████| 557/557 [01:57<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 Loss: 0.6214\nValidation Accuracy: 0.7177  Validation Macro F1: 0.4635\n                precision    recall  f1-score   support\n\n           Yes       0.84      0.84      0.84       194\nTo some extent       0.11      0.24      0.15        17\n            No       0.61      0.30      0.40        37\n\n      accuracy                           0.72       248\n     macro avg       0.52      0.46      0.46       248\n  weighted avg       0.76      0.72      0.73       248\n\n\n🔁 Training with: SMOOTHING Loss\n\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEpoch 1/15: 100%|██████████| 557/557 [01:57<00:00,  4.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Loss: 1.3602\nValidation Accuracy: 0.7823  Validation Macro F1: 0.2926\n                precision    recall  f1-score   support\n\n           Yes       0.78      1.00      0.88       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.00      0.00      0.00        37\n\n      accuracy                           0.78       248\n     macro avg       0.26      0.33      0.29       248\n  weighted avg       0.61      0.78      0.69       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/15: 100%|██████████| 557/557 [01:57<00:00,  4.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Loss: 1.3620\nValidation Accuracy: 0.4960  Validation Macro F1: 0.2980\n                precision    recall  f1-score   support\n\n           Yes       0.79      0.53      0.64       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.17      0.54      0.26        37\n\n      accuracy                           0.50       248\n     macro avg       0.32      0.36      0.30       248\n  weighted avg       0.65      0.50      0.54       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Loss: 1.3559\nValidation Accuracy: 0.7218  Validation Macro F1: 0.3136\n                precision    recall  f1-score   support\n\n           Yes       0.79      0.91      0.84       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.12      0.08      0.10        37\n\n      accuracy                           0.72       248\n     macro avg       0.30      0.33      0.31       248\n  weighted avg       0.64      0.72      0.67       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/15: 100%|██████████| 557/557 [01:57<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Loss: 1.3650\nValidation Accuracy: 0.7823  Validation Macro F1: 0.2926\n                precision    recall  f1-score   support\n\n           Yes       0.78      1.00      0.88       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.00      0.00      0.00        37\n\n      accuracy                           0.78       248\n     macro avg       0.26      0.33      0.29       248\n  weighted avg       0.61      0.78      0.69       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/15: 100%|██████████| 557/557 [01:57<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Loss: 1.3657\nValidation Accuracy: 0.7823  Validation Macro F1: 0.2926\n                precision    recall  f1-score   support\n\n           Yes       0.78      1.00      0.88       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.00      0.00      0.00        37\n\n      accuracy                           0.78       248\n     macro avg       0.26      0.33      0.29       248\n  weighted avg       0.61      0.78      0.69       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/15: 100%|██████████| 557/557 [01:57<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 Loss: 1.3591\nValidation Accuracy: 0.7823  Validation Macro F1: 0.2926\n                precision    recall  f1-score   support\n\n           Yes       0.78      1.00      0.88       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.00      0.00      0.00        37\n\n      accuracy                           0.78       248\n     macro avg       0.26      0.33      0.29       248\n  weighted avg       0.61      0.78      0.69       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/15: 100%|██████████| 557/557 [01:57<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 Loss: 1.3635\nValidation Accuracy: 0.7823  Validation Macro F1: 0.2926\n                precision    recall  f1-score   support\n\n           Yes       0.78      1.00      0.88       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.00      0.00      0.00        37\n\n      accuracy                           0.78       248\n     macro avg       0.26      0.33      0.29       248\n  weighted avg       0.61      0.78      0.69       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/15: 100%|██████████| 557/557 [01:57<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 Loss: 1.3567\nValidation Accuracy: 0.7823  Validation Macro F1: 0.2926\n                precision    recall  f1-score   support\n\n           Yes       0.78      1.00      0.88       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.00      0.00      0.00        37\n\n      accuracy                           0.78       248\n     macro avg       0.26      0.33      0.29       248\n  weighted avg       0.61      0.78      0.69       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/15: 100%|██████████| 557/557 [01:57<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 Loss: 1.3641\nValidation Accuracy: 0.7823  Validation Macro F1: 0.2926\n                precision    recall  f1-score   support\n\n           Yes       0.78      1.00      0.88       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.00      0.00      0.00        37\n\n      accuracy                           0.78       248\n     macro avg       0.26      0.33      0.29       248\n  weighted avg       0.61      0.78      0.69       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/15: 100%|██████████| 557/557 [01:57<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 Loss: 1.3601\nValidation Accuracy: 0.7823  Validation Macro F1: 0.2926\n                precision    recall  f1-score   support\n\n           Yes       0.78      1.00      0.88       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.00      0.00      0.00        37\n\n      accuracy                           0.78       248\n     macro avg       0.26      0.33      0.29       248\n  weighted avg       0.61      0.78      0.69       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/15: 100%|██████████| 557/557 [01:57<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 Loss: 1.3624\nValidation Accuracy: 0.7823  Validation Macro F1: 0.2926\n                precision    recall  f1-score   support\n\n           Yes       0.78      1.00      0.88       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.00      0.00      0.00        37\n\n      accuracy                           0.78       248\n     macro avg       0.26      0.33      0.29       248\n  weighted avg       0.61      0.78      0.69       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/15: 100%|██████████| 557/557 [01:57<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 Loss: 1.3588\nValidation Accuracy: 0.7823  Validation Macro F1: 0.2926\n                precision    recall  f1-score   support\n\n           Yes       0.78      1.00      0.88       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.00      0.00      0.00        37\n\n      accuracy                           0.78       248\n     macro avg       0.26      0.33      0.29       248\n  weighted avg       0.61      0.78      0.69       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/15: 100%|██████████| 557/557 [01:57<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 Loss: 1.3598\nValidation Accuracy: 0.7823  Validation Macro F1: 0.2926\n                precision    recall  f1-score   support\n\n           Yes       0.78      1.00      0.88       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.00      0.00      0.00        37\n\n      accuracy                           0.78       248\n     macro avg       0.26      0.33      0.29       248\n  weighted avg       0.61      0.78      0.69       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/15: 100%|██████████| 557/557 [01:57<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 Loss: 1.3624\nValidation Accuracy: 0.7823  Validation Macro F1: 0.2926\n                precision    recall  f1-score   support\n\n           Yes       0.78      1.00      0.88       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.00      0.00      0.00        37\n\n      accuracy                           0.78       248\n     macro avg       0.26      0.33      0.29       248\n  weighted avg       0.61      0.78      0.69       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/15: 100%|██████████| 557/557 [01:57<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 Loss: 1.3571\nValidation Accuracy: 0.7823  Validation Macro F1: 0.2926\n                precision    recall  f1-score   support\n\n           Yes       0.78      1.00      0.88       194\nTo some extent       0.00      0.00      0.00        17\n            No       0.00      0.00      0.00        37\n\n      accuracy                           0.78       248\n     macro avg       0.26      0.33      0.29       248\n  weighted avg       0.61      0.78      0.69       248\n\n\n🔁 Training with: FOCAL Loss\n\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEpoch 1/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Loss: 0.6758\nValidation Accuracy: 0.0806  Validation Macro F1: 0.0922\n                precision    recall  f1-score   support\n\n           Yes       0.00      0.00      0.00       194\nTo some extent       0.07      1.00      0.13        17\n            No       0.75      0.08      0.15        37\n\n      accuracy                           0.08       248\n     macro avg       0.27      0.36      0.09       248\n  weighted avg       0.12      0.08      0.03       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Loss: 0.6356\nValidation Accuracy: 0.3266  Validation Macro F1: 0.3244\n                precision    recall  f1-score   support\n\n           Yes       0.97      0.20      0.33       194\nTo some extent       0.26      0.41      0.32        17\n            No       0.20      0.97      0.33        37\n\n      accuracy                           0.33       248\n     macro avg       0.48      0.53      0.32       248\n  weighted avg       0.81      0.33      0.33       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Loss: 0.6025\nValidation Accuracy: 0.0806  Validation Macro F1: 0.0922\n                precision    recall  f1-score   support\n\n           Yes       0.00      0.00      0.00       194\nTo some extent       0.07      1.00      0.13        17\n            No       0.75      0.08      0.15        37\n\n      accuracy                           0.08       248\n     macro avg       0.27      0.36      0.09       248\n  weighted avg       0.12      0.08      0.03       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Loss: 0.5580\nValidation Accuracy: 0.1815  Validation Macro F1: 0.1840\n                precision    recall  f1-score   support\n\n           Yes       0.93      0.07      0.13       194\nTo some extent       0.07      0.47      0.12        17\n            No       0.19      0.62      0.30        37\n\n      accuracy                           0.18       248\n     macro avg       0.40      0.39      0.18       248\n  weighted avg       0.76      0.18      0.16       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Loss: 0.5001\nValidation Accuracy: 0.3266  Validation Macro F1: 0.3022\n                precision    recall  f1-score   support\n\n           Yes       1.00      0.23      0.38       194\nTo some extent       0.14      0.53      0.22        17\n            No       0.19      0.73      0.31        37\n\n      accuracy                           0.33       248\n     macro avg       0.45      0.50      0.30       248\n  weighted avg       0.82      0.33      0.36       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 Loss: 0.4332\nValidation Accuracy: 0.3266  Validation Macro F1: 0.2895\n                precision    recall  f1-score   support\n\n           Yes       1.00      0.25      0.40       194\nTo some extent       0.11      0.41      0.18        17\n            No       0.18      0.68      0.29        37\n\n      accuracy                           0.33       248\n     macro avg       0.43      0.45      0.29       248\n  weighted avg       0.82      0.33      0.37       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 Loss: 0.4190\nValidation Accuracy: 0.3387  Validation Macro F1: 0.3030\n                precision    recall  f1-score   support\n\n           Yes       1.00      0.27      0.42       194\nTo some extent       0.11      0.53      0.19        17\n            No       0.20      0.62      0.30        37\n\n      accuracy                           0.34       248\n     macro avg       0.44      0.47      0.30       248\n  weighted avg       0.82      0.34      0.39       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 Loss: 0.3896\nValidation Accuracy: 0.3427  Validation Macro F1: 0.3057\n                precision    recall  f1-score   support\n\n           Yes       1.00      0.28      0.44       194\nTo some extent       0.10      0.53      0.17        17\n            No       0.22      0.59      0.32        37\n\n      accuracy                           0.34       248\n     macro avg       0.44      0.47      0.31       248\n  weighted avg       0.82      0.34      0.40       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 Loss: 0.3579\nValidation Accuracy: 0.3710  Validation Macro F1: 0.3092\n                precision    recall  f1-score   support\n\n           Yes       0.92      0.34      0.50       194\nTo some extent       0.09      0.41      0.14        17\n            No       0.20      0.51      0.29        37\n\n      accuracy                           0.37       248\n     macro avg       0.40      0.42      0.31       248\n  weighted avg       0.75      0.37      0.44       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 Loss: 0.3473\nValidation Accuracy: 0.3548  Validation Macro F1: 0.3141\n                precision    recall  f1-score   support\n\n           Yes       0.98      0.29      0.45       194\nTo some extent       0.11      0.53      0.19        17\n            No       0.21      0.62      0.31        37\n\n      accuracy                           0.35       248\n     macro avg       0.43      0.48      0.31       248\n  weighted avg       0.81      0.35      0.41       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 Loss: 0.3445\nValidation Accuracy: 0.3669  Validation Macro F1: 0.3298\n                precision    recall  f1-score   support\n\n           Yes       0.98      0.28      0.44       194\nTo some extent       0.14      0.53      0.22        17\n            No       0.21      0.73      0.33        37\n\n      accuracy                           0.37       248\n     macro avg       0.44      0.51      0.33       248\n  weighted avg       0.81      0.37      0.41       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 Loss: 0.3473\nValidation Accuracy: 0.3105  Validation Macro F1: 0.2786\n                precision    recall  f1-score   support\n\n           Yes       0.98      0.26      0.41       194\nTo some extent       0.08      0.53      0.15        17\n            No       0.20      0.49      0.28        37\n\n      accuracy                           0.31       248\n     macro avg       0.42      0.42      0.28       248\n  weighted avg       0.80      0.31      0.37       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 Loss: 0.3344\nValidation Accuracy: 0.3468  Validation Macro F1: 0.3035\n                precision    recall  f1-score   support\n\n           Yes       0.95      0.29      0.44       194\nTo some extent       0.10      0.47      0.16        17\n            No       0.21      0.59      0.31        37\n\n      accuracy                           0.35       248\n     macro avg       0.42      0.45      0.30       248\n  weighted avg       0.78      0.35      0.40       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 Loss: 0.3509\nValidation Accuracy: 0.3589  Validation Macro F1: 0.3080\n                precision    recall  f1-score   support\n\n           Yes       0.92      0.31      0.47       194\nTo some extent       0.10      0.47      0.16        17\n            No       0.20      0.54      0.30        37\n\n      accuracy                           0.36       248\n     macro avg       0.41      0.44      0.31       248\n  weighted avg       0.76      0.36      0.42       248\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/15: 100%|██████████| 557/557 [01:57<00:00,  4.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 Loss: 0.3292\nValidation Accuracy: 0.3710  Validation Macro F1: 0.3140\n                precision    recall  f1-score   support\n\n           Yes       0.93      0.32      0.48       194\nTo some extent       0.10      0.41      0.16        17\n            No       0.21      0.59      0.31        37\n\n      accuracy                           0.37       248\n     macro avg       0.41      0.44      0.31       248\n  weighted avg       0.76      0.37      0.43       248\n\n","output_type":"stream"}],"execution_count":37},{"id":"52563611-a7bd-4b2f-ac7a-621c2f51104c","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}